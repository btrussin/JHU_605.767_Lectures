9E: Bump Mapping

https://www.fabiensanglard.net/bumpMapping/index.php [Bump Mapping with GLSL]
https://registry.khronos.org/OpenGL-Refpages/gl4/html/glVertexAttribPointer.xhtml [glVertexAttribPointer]
https://developer.nvidia.com/nvidia-texture-tools-exporter [NVIDIA Texture Tools Exporter]
https://docs.gimp.org/en/gimp-filter-normal-map.html [Normal Maps with GIMP]
http://download.nvidia.com/developer/SDK/Individual_Samples/samples.html [NVIDIA Samples]
https://casual-effects.com/research/McGuire2005Parallax/index.html [Steep Parallax Mapping]
http://www.ozone3d.net/tutorials/bump_mapping.php [Bump Mapping using GLSL]
https://3dkingdoms.com/tutorial.htm#space [Object Space and Tangent Space]
https://www.paulsprojects.net/tutorials/simplebump/simplebump.html [Simple Bump Mapping]


--2-- File 69
This video discusses bump mapping, a considerably powerful feature. We also briefly discuss parallax mapping, an extension of bump mapping, and displacement mapping.

--3-- File 71
You can see the detail added to the two images at the top here. Bump mapping could be used to add regular repeating patterns like in the image at the top left, or a noise-like pattern like the image at the top right.

Also notice the detail added to the globe image at the bottom.

--4-- File 73
Many surfaces are rough as opposed to the smooth surfaces that we typically render. Properly rendering a bumpy or dimpled surface would require a highly detailed mesh that would be very expensive to create and store. However, since lighting calculations depend on the surface normal, we could perturb the surface normal per fragment to get a non-smooth surface.

This is an adjustment to the diffuse and specular components, which implies that we are performing our lighting calculations in the fragment shader.

The model itself does not change, it remains smooth, but lighting viewed from a relatively high incident angle looks very convincing.

--5-- File 77
Blinn's bump mapping method was developed in 1978 and stored two signed values for the dimensions of a Normal vector projected onto the tangent plane to the surface. The third dimension was derived from the other two.

A normal map can be created using a height field, or height map. A height map is a map of texel values for the height of each pixel from the tanget plane. The normals are computed by comparing the height differences to adjacent pixels.

--6-- File 78
Bump mapping needs a normal map for the object. The normal for each texel is stored in the RGB channels corresponding to the x, y, and z values of the normal in the tangent plane.  Z can only be positive, so the 0-255 range scales to 0-to-1.  However, the x and y components can be negative, so 0-255 must map to -1 to 1.  Values below 128 are negative and values above 128 are positive.

The reason that normals are stored in the texture's tangent space is that if the normals are stored in object space, non-uniform scaling skews the normals. It is easy enough to transform light positions to texture tangent space and perform those calculations there.

--7-- File 81
You can transform points and vectors into tangent space using a TBN matrix, which stands for tangent, bi-tangent, normal, that is shown here.

We are already storing the normal vector per vertex as a vertex attribute.  Use of bump mapping requires an additional attribute, the vertex tangent. We will discuss how to get the tangent vector on the next slide.

The bi-tangent vector is the cross product of the other two, and is cheap to compute, so there is no need to store it as an extra attribute.

--8-- File 83
The tangent vector corresponds to the positive s direction of the texture. For most of our procedural models, this is known and easily added. For more complex models and texture mapping however, we may need a better approach.

The method shown here accepts two vertex positions and their texture coordinates. The vertices are assumed to be adjacent, connected by an edge, or part of the same triangle.

This is easy enough to implement, so I won't bother explaining it.

--9-- File 84
Of course, you will need to add a vertex attribute, find its location and bind it to your vertex attribute.  I suggest following the pattern of the normal vector and texture coordinate for reference.

--10-- File 85
Here is some sample code for a vertex shader from the GLSL book. Note the difference in the GLSL version from what we're using. Regardless, most of the syntax is the same.

--11-- File 86
Here are a few references for tools to create normal maps.

--12-- File 87
Parallax mapping, also known as relief mapping, is an extension of bump mapping developed in the early 2000's. The method tries to account for small, occluded sections of a deep, bumpy surface, especially when viewed at an angle.

Parallax mapping uses a height map and a normal map in its calculations. It uses the view reference point to offset the texture coordinate slightly, returning texels that are offset from the fragment position accounting for slopes and occluded regions of the surface.

This requires more calculations than bump mapping, but is not a difficult extension to it. The text has a really good section on this, if you're interested.  The link at the bottom of the slide is also a good reference.

--13-- File 90
Displacement mapping is related to bump mapping, but is significantly simpler. Displacement mapping adjusts the vertex position, so you need access to a height map texture in the vertex shader. This is often used for terrain, water, or other large surfaces.

--14-- File 92
Here are a few more resources on bump mapping if you're interested in exploring this further and seeing how others have implemented it.

This concludes this video.
