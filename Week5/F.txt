--2--
This video concludes this module's lecture discussing level of detail computation and selection.

--3--
The images here show four distinct levels of detail, from low to very high, that send various numbers of triangles through the rendering pipeline.

--4--
The rationale behind this method is that an object near the camera appears in greater detail than the same object far from the camera. Due to perspective projection, the number of rendered fragments decreases as objects are further from the camera, but an equal strain on the vertex processing could still occur. 

Level of detail addresses this concern. It would boost performance if we only rendered triangles that significantly contribute to the final image.

Some objects have inherent levels of detail, and others can have this added to their algorithms or models.

The three necessary aspects of level of detail are first having discrete levels of detail; second, choosing which level to render; and third, switching between discrete levels.

--5--
Switching between discrete levels of detail is particulary tricky. The most jarring effect is when it is noticeable to the viewer.  Parts of the object, or the entire object pops into or out of view.

Methods for switching include discrete switching, which may lead to popping, blending two levels together, using some sort of transparency to display the object, or morphing between levels. These, or course, have varying complexities and computation times.

--6--
Discrete levels of detail are probably the easiest to implement. You can store multiple versions of an object, either as offsets in a vertex buffer object or as separate buffer objects. Then, based on the distance from the camera, you can choose which model to render. A choice can be made every frame for which model to render.  This is a simple approach, but is subject to popping.

--7--
When switching between one level of detail and another, a way to smoothly do this is to render both objects at the same time and blend them together.  For example, which switching from level 1 to level 2, you render level 1 opaquely and gruadually increase the alpha value of level 2 until you can comfortably stop rendering level 1.

This method negates some of the benefits you get from level of detail selection, but does illuminate the popping issue.

--8--
The alpha LOD method uses just one model representation, but adjusts the alpha value when the object is far from the camera to eliminate the effect of the object completely popping in and out of view.

The only performance benefit from this is when the object is completely out of view.

--9--
The continuous level of detail method stores multiple levels of detail be collapsing edges. To go from a higher to lower polygon count, you collapse the edge of a triangle to form a single triangle out of two. Going from a lower level to a higher level of detail uses what is a called a vertex split, the inverse of the edge collapse.

This requires a large number of models to be stored, but enables an edge to smoothly collapse, or expand, giving a continuously changing effect.

Not all models look good using this approach and the memory requirement is high.

--10-- 
One extension of the continuous level of detail method is called geomorphing. This uses a smaller set of levels of detail than the previous method but requires and explicit association between the vertices of the various levels. 

This provides the ability to both smooth interpolate between levels of detail or explicitly select one.

The main disadvantages to this approach are the initial setup of various levels of detail with the connected vertices and the high cost of interpolating between two levels.

--11--
Selecting which level of detail to use depends on the distance of the model from the camera.  This should be determined before running your application.

There are two methods for selecting this level, the first is the distance from the view reference point.  The second method is to project the geometry onto the view plane, which will be covered on the next slide.

The linear distance of a model from the camera is easy to compute.  A single scene graph node can perform this function on its update or draw call method and make the appropriate selection.

--12--
You can also determine which level of detail to select based on the object's projection onto the view plane. This method becomes very simple if your object has a bounding volume, especially a sphere, associated with it. 

The projected size decreases proportionally as the distance from the camera increases.  The level of detail can then be selected based on the number of pixels the model would cover.

--13--
Estimating the projected size of a box onto the view plane is a little more complex, but still relatively simple. You can determine how many vertices will be projected by determining the view reference point relative to the box. If the camera sees only one face of the box, then four points will be projected onto the view plane.  Otherwise, six points will be projected onto the view plane. Then, you can compute area of the projection polygon to make your determination.

This method can be optimized using a lookup table where 27 regions are defined with respect to the box, and once you know the region the camera position is in, the appropriate 4 or 6 vertices are already known. This uses a concept called voronoi regions which we will discuss in Module 10 and is given good treatment in Ericson's Real-time Collision Detection text.

--14--
Application-based culling can be overdone, but doesn't need to be. Most applications are fine doing view frustum culling and level-of-detail selection for only very complex objects. The hardware-based rendering pipeline can usually handle the rest.

Trying to perform too many culling operations can decrease performance if your algorithms are not quite right, or fully optimized; so there is a lot of room for error.

For more complex scenes, it may be best to try a hard-accelerated approach.

And portal culling should be confined to indoor scenes with many rooms.

This concludes this video.
