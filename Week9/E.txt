--2--
This video discusses bump mapping, a considerably powerful feature. We also briefly discuss parallax mapping, and extension of bump mapping, and displacement mapping.

--3--
You can see the detail added to the two images at the top here. Bump mapping could be used to add regular repeating patterns like in the image at the top left, or a noise-like pattern like the image at the top right.

Also notice the detail added to the globe image at the bottom.

--4--
Many surfaces have a rough surface as opposed to the smooth surfaces that we typically render. Properly rendering a bumpy or dimpled surface would require a highly detailed mesh that would be very expensive to create and store. However, since lighting calculations depend on the surface normal, we could perturb the surface normal per fragment to get a non-smooth surface.

This is an adjustment to the diffuse and specular components, which implies that we are performing our lighting calculations in the fragment shader.

The model itself does not change, it remains smooth, but lighting viewed from a relatively high incident angle looks very convincing.

--5--
Blinn's bump mapping method was developed in 1978 and stored two signed values for the dimensions of Normal vector projected onto tangent plane to the surface. The third dimension was derived from the other two.

A normal map can be created using a height field, or height map. A height map is a map of texel values for the height of each pixel from the tanget plane. The normals are computed by comparing the height differences to adjacent pixels.

--6--
Bump mapping needs a normal map for the object. The normal for each texel is stored in the RGB channels corresponding to the x, y, and z values of the normal in the tangent plane.  Z can only be positive, so the 0-255 range scales to 0-to-1.  However, the x and y components can be negative, so 0-255 must map to -1 to 1.  Values below 128 are negative and value above 128 are positive.

The reason that normals are store in texture tangent space is that if the normals are stored in object space, non-uniform scaling skews the normals. It is easy enough to transform light positions to texture tangent space and perform those calculations there.

--7--
You can transform points and vectors into tangent space using a TBN matrix, which stands for tangent, bi-tangent, normal, that is shown here.

We are already storing the normal vector per vertex as a vertex attribute.  Use of bump mapping requires an additional attribute, the vertex tangent. We will discuss how to get the tanget vector on the next slide.

The bi-tangent vector is the cross product of the other two, and is cheap to compute, so there is no need to store it as an extra attribute.

--8--
The tangent vector corresponds to the positive s direction of the texture. For most of our procedural models, this is known and easily added. For more complex models and texture mapping however, we may need a better approach.

The method shown here accepts two vertex positions and their texture coordinates. The vertices are assumed to be adjacent, connected by an edge, or at least part of the same triangle.

This is easy enough to implement, so I won't bother explaining it.

--9--
Of course, you will need to add a vertex attribute, find its location and bind it to your vertex attribute.  I suggest following the pattern of the normal vector and texture coordinate for reference.

--10--
Here is some sample code for a vertex shader from the GLSL book. Note the difference in the GLSL version from what we're using. Regardless, most the syntax is the same.

--11--
Here a few references for tools to create normal maps.

--12--
Parallax mapping, also known as relief mapping, is an extension of bump mapping developed in the early 2000's. The method tries to account for small, occluded sections of a deep, bumpy surface, especially when viewed at an angle.

Parallax mapping uses a height map and a normal map in its calculations. It uses the view reference point to offset the texture coordinate slightly, returning texels that are offset from the fragment position accounting for slopes and occluded regions of the surface.

This requires more calculations than bump mapping, obviously, but is not a difficult extension to it. The text has a really good section on this, if you're interested.  The link at the bottom of the slide is also a good reference.

--13--
Displacement mapping is related to bump mapping, but is significantly simpler. Displacement mapping adjusts the vertex position, so you need access to a height map texture in the vertex shader. This is often used for terrain and water, large surfaces.

--14--
Here are a few more resources on bump mapping if you're interested in exploring this further and seeing how others have implemented it.

This concludes this video.
