--2--
In this final video of Module 9, we will discuss procedural texturing on the GPU.

--3--
The have already discussed procedural texturing in ray tracing.  This was easy to do since we were programming on the CPU and had access to any information we wanted.

In the last 20 especially, we have seen more advanced GPUs, which allows us to do more programming in shaders. That, along with more built-in functions and the fact that we are seeing faster and more powerful graphics cards enables us to perform procedural textures in real-time directly in shader programs.

This has a few advantages over 2D textures, namely a significantly smaller memory footprint, resolultion that scales with your application, and the possibility to generalize your algorithms with parameters, uniform variables and vertex attributes.

Some disavantages include computational costs, lack of filtering options such as mip-maps, and non-determinism across platforms due to inconsistent built-in function implementation.

--4--
Since we already have an idea how to generate texture patterns through algorithms, I think it is best to analyze a few examples using shader programs.

There are many built-in functions that we can use via the OpenGL shading language, or we could define our own.  The general suggestion is to use built-in functions if availabe, because they may utilize some hardware acceleration. We also have to option to define or precalculate some of the algorithm in the application and pass those values to the shader using uniform variables, vertex attributes, or textures.

The three examples I will cover are from the OpenGL Shading Languege text, 3rd Edition, by Rost and Licea-Kane, an excellent resource for GPU programming, in my opinion.

--5--
Here is an example of the procedurally generated stripe pattern on a torus, that we discuss on the next slide.

--6--
There are two main strategies on rendering stripes, one is to anchor the stripes to the object using some local coordinates, the other is to anchor the stripes to the world coordinates or some other exterior coordinate system.  The former functions like normal texture mapping, while the latter functions like carving out a sculture from some 3D volume.

--7--
The fragmant shader code is patterned after the example from the OpenGL Shading Language text.

This uses the fraction part of the scaled s-coordinate of the texture coordinates, and performs a smooth transition bewteen the stripe and base colors.

--8--
The next example is the famous Luxo ball from Pixar's first published short film, which has a cameo in all, or most of, the Pixar films, I believe.

--9--
The ball has a yellow base color, a blue stripe in the center, and two red stars on either side.The strategy is to define each component separately. 

The blue stripe is defined as the regions between two places. If a fragment lies between these two planes, it is given the blue color.

The star is a little trickier, but follows the same pattern. The suggestion is to define the star using 5 independent planes that pass through the star's end-points.  Every point on the star is above exactly four planes, or above all five planes. 

This can difficult to visualize in 3D, but can be simplified using a 2D example.  See the diagram on the right. Lines pass through the five star endpoints and are oriented towards the center. Regions above exactly 4 lines or all five lines define the inside of the star.  If the region is above less than 4 lines, it is outside the star.

--10--
The code is a bit long, so I won't include it, but the algorithm is quite simple.

Check if the point is in-between the two stripe planes first.  If not, check the star patterns. Finally, output the base color if the other conditions don't pass.

--11--
Bump mapping can also be performed without the use of a normal map, but the process is quite similar to texture-base approach.  We still to sample per-fragment and perform lighting in tangent space (or transform the normal vector to world space), but the normal vectors themselves can be produced procedurally.

Similar to the stripe pattern, you can define regular regions. A good example is a dimple pattern. You can define regularly spaced dimples and derive the normal vaector based on the distance from the fragment's coordinates from the dimple center. It greater than the dimple radius, the normal vector would be the same as the surface normal.

Or, for a less regular pattern, you could use the built-in noise3 function. You will most likely need to scale the input to get right effect, and you should consider the probability that the noise3 function will produce different results on different GPUs or platforms.

The rest of the bump-mapping algorithm is the same as the texture-based method.

This concludes this video.
