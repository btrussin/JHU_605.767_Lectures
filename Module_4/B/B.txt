
4B: Implementing Radiosity
https://education.siggraph.org/static/HyperGraph/radiosity/overview_2.htm [Radiosity Overview]
https://www.cs.cmu.edu/~radiosity/emprad-tr.html [An Empirical Comparison of Radiosity Algorithms]



--2-- File 0
In this video, we discuss implementation details of Radiosity.  Most of the information in this video comes from Alan Watt's 3D Computer Graphics 3rd Edition text, which is the best resource I have found that explains radiosity and how to implement it.

--3-- File 3
The most difficult part of the radiosity algorithm is the calculation of the form factors. We mentioned in the previous video that we must calculate the form factor between every pair of patches in the scene. 

A modest scene can easily have 10's of thousands of patches. If we just consider a scene with 10,000 patches and each form factor being reduced to a single floating point value, the required storage is alread 400 million bytes, nearly half a gigabyte. And it is not uncommon for the number of patches to reach the millions. Even though the majority of the form factors will be zero, this is still an issue as scenes increase in size and complexity.

--4-- File 4
For now, let's just consider the form factor between two patches. This should remind you of the diffuse component calculation of the Phong reflection model.

Here we determine the light radiance that is reflected off of patch 'j', onto patch 'i', then reflected again off of patch 'i'.

The vector between the midpoints of the two patches gives the incident angles to the surface normals. The cosine of these angles, along with the squared distance between the patches scale the radiant light. The formula is shown here.

--5-- File 7
The true form factor integrates over the areas of the two patches. This is difficult to compute analytically, so we will discuss approximate methods on the next few slides.

We can store the factor independent of the area by dividing by Area-'i'.

The sum of the factors must equal one, so each factor is only a fraction of the total energy leaving the patch.

--6a-- File 9
There have been multiple efforts to establish a reasonable method for determining form factors between patches, each improving upon the last. The first approach was to explicitly calculate the integrals. This was expensive and did not handle intervening patches too well.

A common method now is to use a hemicube, a discretized grid, similar in concept to pixels on a view plane for ray tracing. In fact, the hemicube grid cells are even called pixels.

--6b-- File 10
With the hemicube determined, you shoot rays from the center of the patch through the pixels into the scene to determine the closest patch that radiates light onto that pixel.  Once every hemicube pixel has been determined, the summation of them is the incoming radiant energy to the patch.

The hemicube method actually works rather well for patches that are far apart, but the analytical method is better for close patch distances. So a hybrid approach is commonly used.

--7-- File 13
The hemicube method is not only efficient, relatively, but also stands up to physical scrutiny. If the distance between two patches is large, the inner itegral and the outer integral are nearly the same; one closely approximates the other.

Also, we know that the hemicube projection is accurate according to the Nusselt analogue.

--8-- File 15
The Nusselt analogue shows that the projection onto the hemicube is mathematically equivalent to the projection onto a hemisphere.

This justification of physical accuracy makes the hemicube method worthy of improvements. So, much research has been done over the years to improve and refine it.

--9-- File 16
Here is a more-detailed overview of the hemicube method. As discussed, you can divide the space surrounding the center of a patch into pixels and project each patch in the scene onto that space and determine the value for each pixel.  Only patches in direct line of sight are considered and only the closest patch value is retained.

The final form factor for the patch is the sum of all the pixel values.

--10-- File 18
The mathematical part of the form factors, the delta form factors, can be precomputed and stored for later use. These are independent of the hemicube projections.

For a given patch-to-patch form factor, you can use the delta form factor and project the patch onto the hemicube and summate the form factors for each intersecting pixel.

The formulas are straight-forward for the intersecting pixels on top of or on one of the sides of the hemicube.

--11-- File 19
Different algorithmic approaches to computing radiosity typically fall into one of three categories.

The gathering approach attempts to solve the radiosity matrix directly. The form factors are stored in the matrix and the radiosity for the patches is computed by solving the system of equations. This can be done iteratively, capturing the amount of change to the radiosities for each iteration. Once the amount of change is small from one iteration to the next, equilibrium has been achieved. One major disadvantage to this approach is that it may take a long while before any intermediate results can be viewed.

The shooting method is also iterative, but instead of calculating the incoming light to a given patch, you do the reverse, calculating the impact of a patch on all other patches. Thus, you can give priority to the patches that emit light and propagate the light energy earlier on in the process.

A variant of the shooting method adds an ad-hoc ambient term so that intermediate results can be seen very early on and account for errors or make changes. The ambient term is reduced for each successive iteration.

--12-- File 20
Radiosity's high storage cost and processing times, likely contribute to the reason it is less-used than ray tracing. Some improvements have been made to mitigate these factors, the most prominent of which is progressive refinement. The rationale behind progressive refinement is similar to that of adaptive super-sampling in ray tracing. 

Using this technique, we can actually reduce the memory requirement and speed up calculations by only spending extra time on the portions of the scene that require more attention.

--13-- File 22
This slide covers some specifics of the algorithm that combines the shooting and ambient approach with progressive refinement.

First we start by computing and storing the form factors for the patches in the scene. We can cut the number of calculations in half using the reciprocity property of form factor i-j to get the form factor j-i as shown in the first bullet point. 

The image is dark at first, so we give each patch some ambient radiosity.

Then determine the patches with the highest radiosity. Typically, these are the light sources, the patches with non-zero emission values. 

Update the matrix colums corresponding to the emitting patches, determining the radiosity for each patch.

Finally, we reduce the ambient light contribution and repeat the process.

--14-- File 23
I will not go into any detail how to construct the patches. Given mesh objects, the patches could be the objects' triangles.

We saw in the previous course that small triangles produced better Gouraud shaded, or vertex shaded, images. With Phong, or pixel shading, we could get away with larger triangles. Radiosity corresponds with Gouraud shading and the size of the patches will affect the quality of the image.

Since the complexity of the radiosity algorithm is on the order of n-squared, we don't want to increase the patch count unnecessarily, only where it makes a difference. 

In practice, higher patch count, with smaller patch size, is most effective where radiosity changes rapidly with respect to surface area.  An adaptive method compares adjacent patch radiosities and subdivides where radiosity differs above a threshold. 

'A priori' methods attempt to predict where these rapid changes will occur. Through observation, we see that rapid changes occur near light emitters and shadow boundaries.

--15-- File 24
Often, these stategies are combined to produce the most efficient and visually accurate images as possible.  Alan Watt explains the common technique of progressive refinement and substructuring in his 3D Computer Graphics text.

--16-- File 25
The dichotomy of ray tracing and radiosity, each having strengths and weaknesses, lends itself to the idea that these two can be combined. This is not so straight-forward, however, and remains an area of research.

--17-- File 26
Here are a few notes comparing various radiosity strategies.  The paper cited here as an excellent resource if you are interested in gaining a deeper understanding of the topics and various approaches.

--18-- File 27
This image was rendered using the Lightscape Visualization System, a software product from the 1990s that uses radiosity.

This concludes this video.
